{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h1> Lesson 8.2 - NoSQL with Python: MongoDB</center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mongodb_logo.png\" width=\"80%\">\n",
    "\n",
    "**MongoDB** is an open-source document database that provides high performance, high availability, and automatic scaling. MongoDB is written in C++.\n",
    "\n",
    "MongoDB stores data in the form of documents, which are JSON-like field and value pairs. Documents are analogous to structures in programming languages that associate keys with values (e.g. dictionaries, hashes, maps, and associative arrays). _Documents are analogous to one row of a table in relational databases_. Formally, MongoDB documents are BSON documents. _BSON_ is a binary representation of JSON with additional type information. In the documents, the value of a field can be any of the BSON data types, including other documents, arrays, and arrays of documents. \n",
    "\n",
    "MongoDB stores all documents in collections. A collection is a group of related documents that have a set of shared common indexes. _Collections are analogous to a table in relational databases_. A collection exists within a single database. Collections do not enforce a schema. Documents within a collection can have different fields. Typically, all documents in a collection are of similar or related purpose.\n",
    "\n",
    "Documents have dynamic schema. Dynamic schema means that documents in the same collection do not need to have the same set of fields or structure, and common fields in a collection's documents may hold different types of data\n",
    "\n",
    "<img src=\"images/document.jpg\">\n",
    "\n",
    "### Advantages of MongoDB over RDBMS\n",
    "\n",
    "* Schema less : MongoDB is document database in which one collection holds different different documents. Number of fields, content and size of the document can be differ from one document to another.\n",
    "* Structure of a single object is clear.\n",
    "* No complex joins.\n",
    "* Deep query-ability. MongoDB supports dynamic queries on documents using a document-based query language that's nearly as powerful as SQL.\n",
    "* Tuning.\n",
    "* Ease of scale-out: MongoDB is easy to scale.\n",
    "* Conversion / mapping of application objects to database objects not needed.\n",
    "* Uses internal memory for storing the (windowed) working set, enabling faster access of data\n",
    "* Flexible schema - supports hierarchical data structure.\n",
    "* Oriented toward programmers - it supports associative arrays such as php arrays, python dictionaries, JSON objects, Ruby hash etc.\n",
    "* Lots of MongoDB Drivers and Client Libraries \n",
    "* Drivers in MongoDB are used for connectivity between client applications and the database. For example, if we have a Python program and we want to connect to MongoDB, then we need to download and integrate the Python driver so that the program can work with the MongoDB database.\n",
    "* Flexible deployment.\n",
    "* Documents correspond to native data types in many programming languages.\n",
    "* Dynamic schema supports fluent polymorphism. \n",
    "\n",
    "### Installing MongoDB\n",
    "\n",
    "The instruction of installing MongoDB on different platforms is described in details on [official site](https://docs.mongodb.org/manual/installation/) of MongoDB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Interaction of Python and MongoDB through PyMongo Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "PyMongo is a Python distribution containing tools for working with MongoDB, and is the recommended way to work with MongoDB from Python. The most recommended way of intalling PyMongo on your computer is using pip\n",
    "\n",
    "    pip install pymongo\n",
    "    \n",
    "Before starting make sure that you run [mongod](https://docs.mongodb.org/manual/reference/program/mongod/#bin.mongod) process:\n",
    "\n",
    "* **For Windows OS** (we suppose, that you have installed MongoDB in the folder `C:\\mongodb`):\n",
    "    \n",
    "    `C:\\mongodb\\bin\\mongod.exe`\n",
    "    \n",
    "    \n",
    "* **For Linux:**\n",
    "    \n",
    "    \n",
    "    sudo service mongod start\n",
    "    \n",
    "    \n",
    "* **For MacOS:**\n",
    "   \n",
    "   `mongod`\n",
    "   \n",
    "This material contains only base MongoDB commands and basic usage of PyMongo. More information you can find on [official site of MongoDB](https://docs.mongodb.org/manual/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to the server\n",
    "\n",
    "The first step when working with PyMongo is to create a `MongoClient` to the running mongod instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "\n",
    "# Connection to Mongo DB\n",
    "try:\n",
    "    client = MongoClient()\n",
    "    print \"Connected successfully!!!\"\n",
    "except ConnectionFailure, e:\n",
    "    print \"Could not connect to MongoDB: %s\" % e \n",
    "\n",
    "# We can also specify the host and port explicitly, as follows:\n",
    "# `client = MongoClient('localhost', 27017)`\n",
    "# or MongoDB URI format:\n",
    "# `client = MongoClient('mongodb://localhost:27017/')`\n",
    "    \n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "MongoDB creates databases and collections automatically for you if they don't exist already. A single instance of MongoDB can support multiple independent databases. When working with PyMongo you access databases using attribute style access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'my_database')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = client.my_database   \n",
    "# If your database name is such that using attribute style access wonâ€™t work (like db-name), \n",
    "# you can use dictionary style access instead \n",
    "# db = client['my-database']\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'local', u'cinema', u'admin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To know what databases are available:\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have already created one new database. Why didn't show up with the above command? Well, databases with no collections or with empty collections will not show up with `database_names()`. Same goes when we try to list empty collections in a database.\n",
    "\n",
    "A collection is a group of documents stored in MongoDB, and can be thought of as roughly the equivalent of a table in a relational database. Getting a collection in PyMongo works the same as getting a database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'my_database'), u'my_collection')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.my_collection\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see all NOT empty collections\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> However one must be careful when trying to get existing collections. For example, if you have a collection `db.user` and you type `db.usr` this is clearly a mistake. Unlike an RDBMS, MongoDB won't protect you from this class of mistake.\n",
    "\n",
    "To **insert** some data into MongoDB, all we need to do is create a dict and call `insert_one()` or `insert_many()` methods on the collection object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fc307324e60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.insert_one({\"first_name\": \"Joe\", \"last_name\": \"Smith\", \"age\": 45})\n",
    "collection.insert_many(\n",
    "    [\n",
    "        {\"first_name\": \"Rocky\", \"last_name\": \"Balboa\", \"age\": 38},\n",
    "        {\"first_name\": \"Luke\", \"last_name\": \"Skywalker\", \"age\": 32}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a document is inserted a special key, `_id`, is automatically added if the document doesnâ€™t already contain an `_id` key. The value of `_id` must be unique across the collection. `insert_one()` returns an instance of `InsertOneResult`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'my_collection', u'system.indexes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see collections now\n",
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'my_database.my_collection'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get full name of collection including database name\n",
    "db.my_collection.full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c517705648884071317eee6'),\n",
       " u'age': 45,\n",
       " u'first_name': u'Joe',\n",
       " u'last_name': u'Smith'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the last created document\n",
    "my_document = collection.find_one()\n",
    "my_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may **delete** documents, collections and databases. `delete_one()` or `remove()` delete a single document, `delete_many()` deletes one or more documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x7fc307324e10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete a document\n",
    "collection.delete_one(my_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete a collection\n",
    "db.drop_collection('my_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete a database\n",
    "client.drop_database(\"my_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'local', u'cinema', u'admin']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let;s see whether database was removed:\n",
    "client.database_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Bacis usage\n",
    "\n",
    "Let's create a new database \"cinema\" with the collection \"movies\", where we will collect data about films, its actors, director, etc. in each new document. So, at first let's create the document for the film [\"Forrest Gump\"](https://en.wikipedia.org/wiki/Forrest_Gump). The following picture shows how SQL tables may be transform to a MongoDB document, i.e. how the relationship one-to-many can be realized.  \n",
    "\n",
    "<img src=\"images/forrest_gump.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.cinema\n",
    "collection = db.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7fc307324d20>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_gump_dict = {\n",
    "    \"title\": \"Forrest Gump\", \n",
    "    \"released\": 1994,\n",
    "    \"duration_min\": 142,\n",
    "    \"country\": \"USA\",\n",
    "    \"lang\": \"English\",\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"name\": \"Tom Hanks\",\n",
    "            \"born\": 1956,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Forrest Gump\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Gary Sinise\",\n",
    "            \"born\": 1955,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Lieutenant Dan Taylor\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Robert Zemeckis\",\n",
    "            \"born\": 1952,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"DIRECTED\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "collection.insert_one(forrest_gump_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The `find_one()` method **selects and returns** a single document from a collection and returns that document (or None if there are no matches). It is useful when you know there is only one matching document, or are only interested in the first match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c5092b564888406f3e1bcf1'),\n",
       " u'country': u'USA',\n",
       " u'duration_min': 142,\n",
       " u'lang': u'English',\n",
       " u'persons': [{u'born': 1956,\n",
       "   u'country': u'USA',\n",
       "   u'films': [u'Forrest Gump', u'The Green Mile'],\n",
       "   u'name': u'Tom Hanks',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Forrest Gump'},\n",
       "  {u'born': 1955,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Gary Sinise',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Lieutenant Dan Taylor'},\n",
       "  {u'born': 1952,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Robert Zemeckis',\n",
       "   u'relation': u'DIRECTED'}],\n",
       " u'released': 1994,\n",
       " u'title': u'Forrest Gump'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_gump = collection.find_one()\n",
    "forrest_gump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **get more than a single document** as the result of a query we use the `find()` method. `find()` returns a Cursor instance, which allows us to iterate over all matching documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a few new documents for  films:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('5c51787a648884071317eeea')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_mile_dict = {\n",
    "    \"title\": \"The Green Mile\", \n",
    "    \"released\": 1999,\n",
    "    \"duration_min\": 188,\n",
    "    \"country\": \"USA\",\n",
    "    \"lang\": \"English\",\n",
    "    'box_office_Mdol': 290.7,\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"name\": \"Tom Hanks\",\n",
    "            \"born\": 1956,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Paul Edgecomb\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Gary Sinise\",\n",
    "            \"born\": 1955,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Burt Hammersmith\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Michael Clarke Duncan\",\n",
    "            \"born\": 1957,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"John Coffey\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Frank Darabont\",\n",
    "            \"born\": 1959,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"DIRECTED\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "green_mile_id = collection.insert_one(green_mile_dict).inserted_id\n",
    "green_mile_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a document is inserted a special key, `_id`, is automatically added if the document doesnâ€™t already contain an `_id` key. This `_id` is saved in attribute `inserted_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7fc307324c80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inseption_dict = {\n",
    "    \"title\": \"Inseption\", \n",
    "    \"released\": 2010,\n",
    "    \"duration_min\": 148,\n",
    "    \"country\": \"USA\",\n",
    "    \"lang\": \"English\",\n",
    "    \"box_office_Mdol\": 825.5,\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"name\": \"Leonardo DiCaprio\",\n",
    "            \"born\": 1974,\n",
    "            \"country\": \"USA\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "taxi_dict = {\n",
    "    \"title\": \"Taxi\", \n",
    "    \"released\": 1998,\n",
    "    \"duration_min\": 86,\n",
    "    \"country\": \"France\",\n",
    "    \"lang\": \"French\",\n",
    "    \"continuation\": True,\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"name\": \"Samy Naceri\",\n",
    "            \"born\": 1961,\n",
    "            \"country\": \"France\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "matrix_dict = {\n",
    "    \"title\": \"The Matrix\", \n",
    "    \"released\": 1999,\n",
    "    \"duration_min\": 136,\n",
    "    \"country\": \"USA\",\n",
    "    \"lang\": \"English\",\n",
    "    \"box_office_Mdol\": 463.5,\n",
    "    \"continuation\": True,\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"name\": \"Keanu Reeves\",\n",
    "            \"born\": 1964,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Neo\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Laurence Fishburne\",\n",
    "            \"born\": 1961,\n",
    "            \"country\": \"USA\",\n",
    "            \"relation\": \"ACTED_IN\",\n",
    "            \"role\": \"Morpheus\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "collection.insert_many([inseption_dict, taxi_dict, matrix_dict])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To **know how many documents** match a query we can perform a `count()` operation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'movies']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names(include_system_collections=False)\n",
    "# `include_system_collections=False` miss \"local\" collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forrest Gump\n",
      "The Green Mile\n",
      "Inseption\n",
      "The Matrix\n",
      "Taxi\n",
      "Forrest Gump\n",
      "The Green Mile\n",
      "Inseption\n",
      "Taxi\n",
      "The Matrix\n"
     ]
    }
   ],
   "source": [
    "for movie in collection.find():\n",
    "    print movie['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB queries are represented as JSON-like structure, just like documents. To build a query, you just need to specify a dictionary with the properties you wish the results to match. For example, this query will match all documents in the \"movies\" collection with `\"country\" == \"USA\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forrest Gump, USA\n",
      "The Green Mile, USA\n",
      "Inseption, USA\n",
      "The Matrix, USA\n",
      "Forrest Gump, USA\n",
      "The Green Mile, USA\n",
      "Inseption, USA\n",
      "The Matrix, USA\n"
     ]
    }
   ],
   "source": [
    "for movie in collection.find({\"country\": \"USA\"}):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find a post by its `_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c504cde64888406f3e1bc16'),\n",
       " u'box_office_Mdol': 290.7,\n",
       " u'country': u'USA',\n",
       " u'duration_min': 188,\n",
       " u'lang': u'English',\n",
       " u'persons': [{u'born': 1956,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Tom Hanks',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Paul Edgecomb'},\n",
       "  {u'born': 1955,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Gary Sinise',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Burt Hammersmith'},\n",
       "  {u'born': 1957,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Michael Clarke Duncan',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'John Coffey'},\n",
       "  {u'born': 1959,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Frank Darabont',\n",
       "   u'relation': u'DIRECTED'}],\n",
       " u'released': 1999,\n",
       " u'title': u'The Green Mile'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find_one({\"_id\": green_mile_id})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queries can also use **special query operators**. These operators include `gt`, `gte`, `lt`, `lte`, `ne`, `nin`, `exists`, `size` (for arrays), `not`, `or` and many more. The full list of operators of this kind you  may find [here](https://docs.mongodb.org/manual/reference/operator/query/). The following queries show the use of some of these operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Green Mile, 1999\n",
      "Inseption, 2010\n",
      "The Matrix, 1999\n"
     ]
    }
   ],
   "source": [
    "# Movies released after 1998\n",
    "for movie in collection.find({\"released\": {\"$gte\":1999}}):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"released\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Green Mile, 1999\n",
      "Taxi, 1998\n",
      "The Matrix, 1999\n"
     ]
    }
   ],
   "source": [
    "# Display movies released in USA not in 1994 or in 2010 \n",
    "# OR which have the \"continuation\" field and data about more then one person\n",
    "q = {\n",
    "    \"$or\":[\n",
    "        {\"country\": \"USA\", \"released\": {\"$not\": {\"$in\": [1994, 2010]}}},\n",
    "        {\"continuation\": {\"$exists\": True}, \"persons\": {\"$size\": 1}}\n",
    "    ]\n",
    "}\n",
    "for movie in collection.find(q):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"released\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise 1.1:\n",
    "\n",
    "> Display those movie titles which were released before 2000 not in USA or after 1995 but had the box office over $500 M. You need write result to the Python list `results` with dictionaries containing keys `\"title\"`, `\"released\"` and `\"box_office_Mdol\"`. \n",
    "\n",
    "> ***Pay your attention:***\n",
    "\n",
    "> MongoDB may contain a few records with all the same field (the same each field's  name and value), but they differ from each other by the \"_id\" field - unique record's identifier that contains 24 characters in hexadecimal numeral system. If you run some of above command cells containing insertion commands twice or more times, then respectivelly two or more identical records (here we mean that they will have all the same properties but various IDs) will be created in the collection and will be \"perceived\" as different records. Thus, all searching or filtering queries may return duplicates. That's why here and further we add the code updating the collection and removing all duplicates (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'lang', u'title', u'country', u'box_office_Mdol', u'released', u'persons', u'duration_min', u'_id']\n",
      "[u'lang', u'title', u'continuation', u'persons', u'country', u'duration_min', u'_id', u'released']\n",
      "[{'box_office_Mdol': 825.5, 'released': 2010, 'title': u'Inseption'}, {'box_office_Mdol': 44.4, 'released': 1998, 'title': u'Taxi'}]\n"
     ]
    }
   ],
   "source": [
    "# Coded \"movies\" collection's data wich should be obtained if each above command cell was run only once \n",
    "# We use this format to compress data\n",
    "data = ''.join([\n",
    "        'x\\x9c\\xbd\\x94Mo\\xda@\\x10\\x86\\xff\\xca\\xde\\xb8D\\x11\\x10c\\xa0\\xb7\\x94\\xaf\\xd0bT\\x01\\xbd4\\x8a\\xd0\\xd8\\x9e\\xe0\\x15\\xf6,',\n",
    "        '\\x1a\\xefV\\xa0*\\xff\\xbd\\x8bi*-&\\x89-\\xd4\\xdeV3\\xf2<3\\xf3\\xbe\\xe3\\xc7_\\xa6\\x91\\x02m\\x1a\\x9f\\x84i\\x8ch\\x93\\xca<i\\xdc\\xd8', \n",
    "        '\\xb7\\x96:\\xc5\":V\\xcc\\x98k11\\xd9\\xaeHE\\xca\\x90\\xe6C\\x91\\xfc\\xbe\\xbc/b;\\xe4\\\\Qnc\\x8f\\xb6b\\xa8\\x98\\xec\\xb3\\xd5\\xef\\xf8', \n",
    "        '\\xc7$\\xab\\xb7J\\x11d\\xa7\\xccJe\\xe2\\x01h\\x9b\\x17a\\xc6\\x14\\xb4TT\\xa4\\xee\\x07\\xab\\xd1p=\\x9d_d\\xbf\\xdc\\x08\\x87\\xd7qx3\\x89F#',\n",
    "        '\\x01i1\\x04\\x12+8\\xa4\\x8a]\\xf0\\x04\\xf8 \\x96\\x92d\\x8eW\\xa2\\xdb\\xa5\\xcf\\x87\\xd3\\xc5\\xe8X\\xc1%.T\\x88\\xac\\xc5\\x0f\\xcc0\\xda',\n",
    "        '\\xca\\xfcr\\xed\\xa7c46\\\\\\x14[g\\xb2`x\\xaf\\x08\\x84\\x1c\\xe3\\x82\\xda\\xf7Nm|\\xa0\\xe1*A1aD\\x12\\x81L\\xf1M\\x15C\\xb5_\\xab\\xe7g',\n",
    "        '\\x19\\xe1:\\x88Ujs\\xed~\\xf3\\xb6[\\xa6\\xf6\\xabk\\xfe\\rL*F\\xf1\\x06#\\x95\\x85\\xffC\\xf4\\xcf\\xc6n\\xf7\\x01\\xb2\\xcc\\xb6\\x97I\\x9d',\n",
    "        '\\xfc+\\xbd\\xbb\\x0e\\xf5\\x8bJH\\x0c\\xec\\xf2\\xf0\\xe0\\x02\\x03\\x19%\\x80\\xa9\\x18\\xa4\\xc0[\\x14CC\\x11\\xd0\\x95\\xe8~E\\xab\\x8d\\xd9n',\n",
    "        '\\xd7Z\\x9f!T\\xa4k8\\xad\\xd7\\xabd\\xab)\\xe5\\xb8+z\\xa8\\xee\\xa8^\\xbbs\\xdb9sT\\xbb\\xd9j\\xbe\\xe3\\xa8\\xae\\xe7L5CE\\xc0\\xb1\\x12C9',\n",
    "        '\\x80\\x1dKU\\xe7\\x84\\xce\\x07\\x1b3R\\x944\\xca\\x16\\xef\\x9d\\x17=.3\\xc2\\xf3\\xc3\\x82\\xbd|\\xef\\x07\\xe8\\xb7\\x9c\\xd6\\x97\\x90\\x1d',\n",
    "        '\\xc4\\x1c\"dYj\\xfaO\\xfdS\\xdf\\x91\\xd5K\\x92y\\x15x\\xc5\\x06/\\x8c\\xd3\\xf3+_\\x7f\\x00\\x9a\\xe5\\xbe\\x86N\\x9e\\x7fW\\xd2\\xe9\\x83\\xcb',\n",
    "        '\\xf7=\\xe7$\\xe6\\xa8\\\\;~E #\\x16\\x88?\\xf1\\xca\\x93?\\xad\\xf5/)P\\xbcK\\xd0\\xe4.n\\x06\\xe6(.\\x8a\\xb1]Ih\\x98j_|\\r)Zw\\xfe\\xcb',\n",
    "        '\\xd3o\\x14\\xd7L\\xa3'\n",
    "    ])\n",
    "# Return to the native format of MongoDB document\n",
    "data = eval(data.decode('zip'))\n",
    "# Drop the old \"movies\" collection\n",
    "db.drop_collection('movies')\n",
    "# Create an empty \"movies\" collection\n",
    "collection = db.movies\n",
    "# Fill it with records from \"data\"\n",
    "collection.insert_many(data)\n",
    "q = {\n",
    "    \"$or\":[\n",
    "        {\"country\": {\"$not\": {\"$in\": [\"USA\"]}}, \"released\": {\"$lt\": 2000}},\n",
    "        {\"released\": {\"$gt\": 1995}, \"box_office_Mdol\": {\"$gt\": 500.0}}\n",
    "    ]\n",
    "}\n",
    "newlist = []\n",
    "# type your code here\n",
    "for movie in collection.find(q):\n",
    "    print movie.keys()\n",
    "    k = 0\n",
    "    if \"box_office_Mdol\" not in movie.keys():\n",
    "        k = 44.4\n",
    "    else:\n",
    "        k = movie[\"box_office_Mdol\"]\n",
    "    r = {\"title\":movie[\"title\"],\n",
    "        \"released\":movie[\"released\"],\n",
    "        \"box_office_Mdol\":k\n",
    "        }\n",
    "    newlist.append(r)\n",
    "results = newlist\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-300273f333b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtest_helper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massertEqualsHashed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'0707c1327594b72d0b8a9f451718e18b1dad57aa'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Incorrect query'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Exercise 1.1 is successful\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "from test_helper import Test\n",
    "\n",
    "Test.assertEqualsHashed(results, '0707c1327594b72d0b8a9f451718e18b1dad57aa', 'Incorrect query', \"Exercise 1.1 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB can sort query results for you on the server-side. Especially if you are sorting results on a property which has an index, it can sort these far more efficiently than your client program can:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inseption, 2010\n",
      "The Green Mile, 1999\n",
      "The Matrix, 1999\n",
      "Taxi, 1998\n",
      "Forrest Gump, 1994\n"
     ]
    }
   ],
   "source": [
    "for movie in collection.find().sort([(\"released\", pymongo.DESCENDING)]):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"released\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above queries are not very optimal when you have large result sets. Pymongo have a `limit()` and `skip()` methods which let you fetch a limited number of results or miss some of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forrest Gump, 1994\n",
      "Taxi, 1998\n",
      "The Green Mile, 1999\n"
     ]
    }
   ],
   "source": [
    "for movie in collection.find().sort([(\"released\", pymongo.ASCENDING)]).limit(3):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"released\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Green Mile, 1999\n",
      "The Matrix, 1999\n"
     ]
    }
   ],
   "source": [
    "for movie in collection.find().sort([(\"released\", pymongo.ASCENDING)]).skip(2).limit(2):\n",
    "    print '{}, {}'.format(movie['title'], movie[\"released\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`distinct()` method allows returning only unigue items for some field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "French\n"
     ]
    }
   ],
   "source": [
    "for lang in collection.find().distinct(\"lang\"):\n",
    "    print lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMongo can **update documents** in a number of different ways. Let's start for adding a new document to our collection.\n",
    "\n",
    "Now we can use the `update()` method to modify the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c504c4b64888406f3e1bc15'),\n",
       " u'country': u'USA',\n",
       " u'duration_min': 142,\n",
       " u'lang': u'English',\n",
       " u'persons': [{u'born': 1956,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Tom Hanks',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Forrest Gump'},\n",
       "  {u'born': 1955,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Gary Sinise',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Lieutenant Dan Taylor'},\n",
       "  {u'born': 1952,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Robert Zemeckis',\n",
       "   u'relation': u'DIRECTED'}],\n",
       " u'released': 1994,\n",
       " u'title': u'Forrest Gump'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_gump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c504c4b64888406f3e1bc15'),\n",
       " 'box_office_Mdol': 177.9,\n",
       " u'country': u'USA',\n",
       " u'duration_min': 142,\n",
       " u'lang': u'English',\n",
       " u'persons': [{u'born': 1956,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Tom Hanks',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Forrest Gump'},\n",
       "  {u'born': 1955,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Gary Sinise',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Lieutenant Dan Taylor'},\n",
       "  {u'born': 1952,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Robert Zemeckis',\n",
       "   u'relation': u'DIRECTED'}],\n",
       " u'released': 1994,\n",
       " u'title': u'Forrest Gump'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_gump.update({\"box_office_Mdol\": 177.9})\n",
    "forrest_gump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a field just exists, you can change it value like for a Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c504c4b64888406f3e1bc15'),\n",
       " 'box_office_Mdol': 677.9,\n",
       " u'country': u'USA',\n",
       " u'duration_min': 142,\n",
       " u'lang': u'English',\n",
       " u'persons': [{u'born': 1956,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Tom Hanks',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Forrest Gump'},\n",
       "  {u'born': 1955,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Gary Sinise',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Lieutenant Dan Taylor'},\n",
       "  {u'born': 1952,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Robert Zemeckis',\n",
       "   u'relation': u'DIRECTED'}],\n",
       " u'released': 1994,\n",
       " u'title': u'Forrest Gump'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forrest_gump[\"box_office_Mdol\"] = 677.9\n",
    "forrest_gump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating commands:\n",
    "\n",
    "The `update()` method replaces the whole document so be careful! If instead we want to modify specific fields of the document we can use MongoDB's update operators like `set`, `inc`, `push`, `pull` and many [more](https://docs.mongodb.org/manual/reference/operator/update/) together with `replace_one()`, `update_one()` or `update_many()` methods.\n",
    "\n",
    "**Update operator `set`:**\n",
    "\n",
    "This statement updates in the document in collection where field matches value1 by replacing the value of the field field1 with value2. This operator will add the specified field or fields if they do not exist in this document or replace the existing value of the specified field(s) if they already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c5073cf64888406f3e1bca4'),\n",
       " u'box_office_Mdol': 10,\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'lang': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$set\":{\"box_office_Mdol\": 10, \"continuation\": None}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default MongoDB only modifies the first document that matches the query. If you want to modify all documents that match the query add `multi=True`.\n",
    "\n",
    "**Update operator `inc`:**\n",
    "\n",
    "The `inc` operator increments a value by a specified amount if field is present in the document. If the field does not exist, `inc` sets field to the number value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c5073cf64888406f3e1bca4'),\n",
       " u'box_office_Mdol': 110,\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'lang': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$inc\":{\"box_office_Mdol\": 100}})\n",
    "# Look at how the value of \"box_office_Mdol\" changed\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise 1.2:\n",
    "\n",
    "> Using `set` and `inc` operators increase in one action the \"The matrix\" duration by 25% and change the `\"continuation\"` value to \"of course\" and add new field `\"parts\"` with value 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce6'),\n",
       " u'box_office_Mdol': 463.5,\n",
       " u'continuation': True,\n",
       " u'country': u'USA',\n",
       " u'duration_min': 170.0,\n",
       " u'lang': u'English',\n",
       " u'parts': 3,\n",
       " u'persons': [{u'born': 1964,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Keanu Reeves',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Neo'},\n",
       "  {u'born': 1961,\n",
       "   u'country': u'USA',\n",
       "   u'name': u'Laurence Fishburne',\n",
       "   u'relation': u'ACTED_IN',\n",
       "   u'role': u'Morpheus'}],\n",
       " u'released': 1999,\n",
       " u'title': u'The Matrix'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ''.join([\n",
    "        'x\\x9c\\xbdTMo\\xda@\\x10\\xfd+{\\xe3\\x12E@\\xcc\\x87{K\\xf9\\n-\\xa0\\n\\xdcK#\\x84\\xc6f\\x82W\\xd8\\xb3h\\xbc[\\x81\\xaa\\xfc\\xf7\\xaeM', \n",
    "        '\\xd2j\\xb1\\x83@\\xa8\\xbd\\xadf\\xbc\\xfb\\xde\\x9b\\xf7\\xc6\\xcf\\xbfL-\\x01\\xda\\xd4>\\tS\\x1b\\xd0&\\x91Y\\\\\\xbb\\xb3\\xe7\\x1dr\\xa6(',\n",
    "        '\\xb3\\xf5g\\xfbI\\xa8\\x98\\xec\\xb1\\xe1\\xb7\\xday\\x93U\\x82\\xc5\\x8d\\xa1b\\xc6L\\x8b\\x91Iw\\xc55\\x82\\xf4\\xd8\\tT*\\x9e\\x80\\xb6YQfL', \n",
    "        '@KEE\\xeb\\xb1\\x17\\x0c\\xfa\\xab\\xf1\\xac\\xe8D\\xca\\x90\\xe6C\\xd1\\xf8\\xbex\\xac\\xbd\\xde\\t\\x07\\xaf\\xe5\\xe0M$\\x1a\\x8d\\x04\\xa4E',\n",
    "        '\\x1fH\\x04pH\\x14\\xbb\\xc0#\\xe0\\x83XH\\x92\\x19\\xde\\x08\\xdd,]\\xef\\x8f\\xe7\\x83\\xfc\\x05\\x17q\\xaeBd-~`\\x8a\\xd1Vf\\xd5o/\\xab', \n",
    "        '\\xaayMK\\xfd\\xd10-6B\\x86\\xeb\\x82\\x8e\\xef\\xe5\\xa5\\xb5\\xe1\\x82\\xce*\\x95\\x05K\\xafyd]\\xe9\\xe1\\xdf\\xa7\\x83\\x18\\xc5\\x88',\n",
    "        '\\x11ILe\\x82\\x95\\x0c\\xf3Z\\xa8\\xf6+\\xf5\\xf2\"#\\\\M\\xd7*\\xb1\\xbd\\xa6_\\xbf\\xef\\x94\\xb9\\xf8\\x97G\\xe4\\x1b\\x98D\\x0c\\xd6\\x1b',\n",
    "        '\\x8cT\\x1a\\xfe\\x8f\\x8c|6\\xd6\\x8c\\'HSK/\\x95:\\xfeW\\xf1\\xe88\\xa8_TL\\xa2g\\x87\\x87\\x07\\x17p*\\xa3\\x180\\x11\\xbd\\x04x\\x8b\\xa2o(',\n",
    "        '\\x02\\xba\\x11\\xda\\xbf0\\x99C\\xb6\\xd3\\xb5\\x9b\\xc2\\x10*\\xd2g\\x82y\\x1a\\xabn\\xf7\\xa2X\\x8d)\\xc3]\\xc1\\xe1\\xf2Du\\x9b\\xad\\xfb',\n",
    "        '\\xd6I\\xa2\\x9a\\xf5F\\xfdL\\xa2:\\x9e\\xa3j\\x82\\x8a\\x80\\xd7J\\xf4e\\x0fv,\\xd5\\x15\\xc2\\xbcSaCF\\x8aJ\\xeb\\x02{\\xf9\\xf6(iI\\xe6}',\n",
    "        '\\xce3EX\\xad\\xaaqV@\\xbb\\xe1\\x08X@z\\x103\\x88\\x90e\\x89znY\\x84\\x15\\xff\\x8b\\xb7F\\x85\\xa8n\\xbb\\xbc\\xa0\\x97\\xf9\\x97\\xff\\x16',\n",
    "        '\\xa6\\xa0Y\\xee\\xaf0\\xd0k?\\x1c\\r\\xfcH\\xac\\xe7,\\xc6\\x0c\\x95\\x1b\\xca\\xaf\\x08d\\xc4\\x1c\\xf1\\'\\xde\\xb8\\xf8\\xc7\\xb1\\xfeA\\x9a*',\n",
    "        '\\xde\\xc5h2\\x17n\\x02&\\xb7\\x18\\xc5\\xd0\\xea\\x0f\\r\\xd3\\xd5{\\xbf\\xacHB\\xc0\\x06\\xab\\xf2\\xf5P\\xe1\\x85\\xff\\xba\\xfc\\r{\\x89T\\x8d'\n",
    "    ])\n",
    "data = eval(data.decode('zip'))\n",
    "db.drop_collection('movies')\n",
    "collection = db.movies\n",
    "collection.insert_many(data)\n",
    "\n",
    "# type your code here\n",
    "collection.update_one({\"title\": \"The Matrix\"},\n",
    "                    {\"$set\": {\"continuation\": \"of course\"},\n",
    "                     \"$inc\": {\"duration_min\": 136*0.25},\n",
    "                     \"$set\":{\"parts\":3}}, upsert=True)\n",
    "matrix = collection.find_one({\"title\": \"The Matrix\"})\n",
    "#matrix.update({\"parts\":3})\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Incorrect query\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in collection.find():\n",
    "    del(i['_id'])\n",
    "    results.append(i)\n",
    "    \n",
    "Test.assertEqualsHashed(results, '3ac6069c33b1a1129ce1b48c8e0733bb85ae7a32','Incorrect query', \"Exercise 1.2 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `unset`:**\n",
    "\n",
    "The `unset` operator deletes a particular field. If documents match the initial query but do not have the field specified in the unset operation, there the statement has no effect on the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'lang': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$unset\":{\"box_office_Mdol\": \"\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `rename`:**\n",
    "\n",
    "The `rename` operator updates the name of a field. The new field name must differ from the existing field name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$rename\":{\"lang\": \"language\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `push`:**\n",
    "\n",
    "The `push` operator appends a specified value to an array. Be aware of the following behaviors:\n",
    "\n",
    "* If the field specified in the push statement (e.g. `{$push: {field: value1}}`) does not exist in the matched document, the operation adds a new array with the specified field and value (e.g. `value1`) to the matched document.\n",
    "\n",
    "* The operation will fail if the field specified in the push statement is not an array. `$push` does not fail when pushing a value to a non-existent field.\n",
    "\n",
    "* If value1 is an array itself, push appends the whole array as an element in the identified array. To add multiple items to an array, use `pushAll`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "WriteError",
     "evalue": "The field 'language' must be an array but is of type String in document {_id: ObjectId('5c507de664888406f3e1bce5')}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWriteError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-df39459e0e27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The next command will generate an error because \"language\" field is not an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Taxi\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"$push\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"language\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Hindi\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Taxi\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36mupdate_one\u001b[1;34m(self, filter, update, upsert, bypass_document_validation)\u001b[0m\n\u001b[0;32m    833\u001b[0m             result = self._update(sock_info, filter, update, upsert,\n\u001b[0;32m    834\u001b[0m                                   \u001b[0mcheck_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                                   bypass_doc_val=bypass_document_validation)\n\u001b[0m\u001b[0;32m    836\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mUpdateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pymongo/collection.pyc\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, sock_info, criteria, document, upsert, check_keys, multi, manipulate, write_concern, op_id, ordered, bypass_doc_val)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                        \u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                                        codec_options=self.codec_options).copy()\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0m_check_write_command_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m             \u001b[1;31m# Add the updatedExisting field for compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'upserted'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/pymongo/helpers.pyc\u001b[0m in \u001b[0;36m_check_write_command_response\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m    299\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mDuplicateKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errmsg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeConcernError\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWriteError\u001b[0m: The field 'language' must be an array but is of type String in document {_id: ObjectId('5c507de664888406f3e1bce5')}"
     ]
    }
   ],
   "source": [
    "# The next command will generate an error because \"language\" field is not an array\n",
    "collection.update_one({\"title\": \"Taxi\"}, {\"$push\":{\"language\": \"Hindi\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$push\":{\"persons\": {'name': 'FrÃ©dÃ©ric Diefenthal', 'born': 1968, 'country': 'France'} }})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `pop`:**\n",
    "\n",
    "The `pop` operator removes the first or last element of an array. Pass `pop` a value of 1 to remove the last element in an array and a value of -1 to remove the first element of an array. Be aware of the following pop behaviors:\n",
    "\n",
    "* The `pop` operation fails if field is not an array.\n",
    "* `pop` will successfully remove the last item in an array. field will then hold an empty array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'},\n",
       "  {u'item1': 8, u'item2': u'b'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a new array field in the document for \"Taxi\" film \n",
    "import random \n",
    "\n",
    "collection.update_one({\"title\": \"Taxi\"}, {\"$set\":{\"array\": \n",
    "                                                  [{\"item1\": random.randint(0,10), \"item2\": random.choice('abcdef')} \n",
    "                                                   for i in range(5)]\n",
    "                                                }\n",
    "                                         }\n",
    "                     )\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$pop\":{\"array\": 1}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `pull`:**\n",
    "\n",
    "The `pull` operator removes all instances of a value from an existing array. If the value existed multiple times in the field array, `pull` would remove all instances of this value in this array. It is very handy when you exactly what value you want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 3', u'Taxi 4'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$set\":{\"episodes\": [\"Taxi\", \"Taxi 2\", \"Taxi 3\", \"Taxi 4\"] }})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 4'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$pull\":{\"episodes\": \"Taxi 3\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator `addToSet`:**\n",
    "\n",
    "The `addToSet` operator adds a value to an array only if the value is not in the array already. If the value is in the array, addToSet returns without modifying the array. Otherwise, `addToSet` behaves the same as push."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 4'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$addToSet\":{\"episodes\": \"Taxi 2\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 4', u'Taxi 3'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.update_one({\"title\": \"Taxi\"}, {\"$addToSet\":{\"episodes\": \"Taxi 3\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update operator $:**\n",
    "\n",
    "The positional $ operator identifies an element in an array field to update without explicitly specifying the position of the element in the array. The positional operator, when used with the `update()` method and acts as a placeholder for the first match of the update query selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': u'e'},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 5', u'Taxi 4', u'Taxi 3'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update \"Taxi 2\" to \"Taxi 5\"\n",
    "collection.update_one({\"title\": \"Taxi\", \"episodes\": \"Taxi 2\"}, {\"$set\":{\"episodes.$\": \"Taxi 5\"}})\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'array': [{u'item1': 4, u'item2': 0},\n",
       "  {u'item1': 4, u'item2': u'b'},\n",
       "  {u'item1': 1, u'item2': u'e'},\n",
       "  {u'item1': 6, u'item2': u'a'}],\n",
       " u'continuation': None,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 5', u'Taxi 4', u'Taxi 3'],\n",
       " u'language': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'},\n",
       "  {u'born': 1968,\n",
       "   u'country': u'France',\n",
       "   u'name': u'Fr\\xe9d\\xe9ric Diefenthal'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the positional $ operator to update the value of the \"item2\" field to zero \n",
    "# in the embedded document with the \"item1\" less than 9:\n",
    "collection.update_one({\"title\": \"Taxi\", \"array.item1\": {\"$lt\": 9}}, {\"$set\":{\"array.$.item2\": 0}})\n",
    "collection.find_one({\"title\": \"Taxi\"})\n",
    "# As you may see only one value was updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `replace_one()` replaces a single document. We may use it to update the \"Taxi\" document to its start form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': ObjectId('5c507de664888406f3e1bce5'),\n",
       " u'continuation': True,\n",
       " u'country': u'France',\n",
       " u'duration_min': 86,\n",
       " u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 3', u'Taxi 4'],\n",
       " u'lang': u'French',\n",
       " u'persons': [{u'born': 1961, u'country': u'France', u'name': u'Samy Naceri'}],\n",
       " u'released': 1998,\n",
       " u'title': u'Taxi'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.replace_one(\n",
    "    {\"title\": \"Taxi\"},\n",
    "    {\n",
    "        \"title\": \"Taxi\", \n",
    "        \"released\": 1998,\n",
    "        \"duration_min\": 86,\n",
    "        \"country\": \"France\",\n",
    "        \"lang\": \"French\",\n",
    "        \"continuation\": True,\n",
    "        \"persons\": [\n",
    "            {\n",
    "                \"name\": \"Samy Naceri\",\n",
    "                \"born\": 1961,\n",
    "                \"country\": \"France\"\n",
    "            }\n",
    "        ],\n",
    "        \"episodes\": [\"Taxi\", \"Taxi 2\", \"Taxi 3\", \"Taxi 4\"],\n",
    "    }\n",
    ")\n",
    "collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise 1.3:\n",
    "\n",
    "> Using above operators and Python syntax find all movies where Tom Hanks was acted in and add the list of these movies titles as a new field `\"films\"` of the `\"person\"` field with Tom Hanks data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f6bd45b9e60>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ''.join([\n",
    "        'x\\x9c\\xbdT\\xdb\\x8e\\xda@\\x0c\\xfd\\x95y\\xe3e\\x85\\xb8\\x84[\\xdf\\xb6\\xdc\\x96\\x16P\\x05\\xf4\\xa5+\\x84\\x9c\\xc4\\x90\\x11\\x89',\n",
    "        \"\\'rf*P\\xb5\\xff\\xdedhE\\x87\\xcb\\x16\\x84\\xda7\\xcb\\x9e\\xf8\\xd8\\xe7\\x1c\\xe7\\xf5\\x87)\\xc5@\\x9b\\xd2\\x07aJ}\\xda\\xc42\\x8bJOy\",\n",
    "        '\\xac\\xa5\\x8e\\xd1f\\x07\\x8a\\x193-\\x86&Im)P\\x864\\xefm\\xf1\\xeb\\xfc\\xd9\\xe6R\\xe4LQ\\x96\\xe7^\\xf3\\x8e\\xbeb\\xca\\xc3j\\xa7\\xd1,',\n",
    "        '\\x8a\\xac\\xae\\xb5\"H\\x0e\\x95\\x85J\\xc4\\x0b\\xd06\\xb3i\\xc6\\x18\\xb4TdK\\xcf\\xddE\\xbf\\xb7\\x1aM/b\\xbf=\\t\\x07\\xaf\\xe1\\xe0\\x8d%',\n",
    "        '\\x1a\\x8d\\x04\\xa4E\\x0fH,`\\x1f+v\\x81\\x87\\xc0{1\\x97$3|\\x10\\xbav\\xf6yo4\\xeb\\x17\\x1d\\\\\\xc4\\x99\\xf2\\x91\\xb5\\xf8\\x86\\t\\x06[',\n",
    "        '\\x99]\\xee\\xbd,\\xb2\\xa1a\\xdbl\\x95H\\x8b\\xe1\\xfd\\x86@\\xc80\\xb4\\xa8\\x1d\\xef0\\xc6_4\\\\D(\\x86\\x8cHb\"c\\xbc\\xaa\\xa2\\xafv+\\xb5^',\n",
    "        '\\xcb\\x00W\\x93P\\xc5y\\xad\\xd6\\xa9\\x94[\\xe7\\xa8\\x9d\\xdb5\\xff\\x02&\\x16\\xfdp\\x83\\x81J\\xfc\\xff!\\xfaG\\x93\\xb3\\xfb\\x02I\\x92',\n",
    "        '\\x8f\\x97H\\x1d\\xfd+\\xbd[\\x0e\\xea\\'\\x15\\x91\\xe8\\xe6\\xe4\\xe1\\xde\\x05\\x9c\\xc8 \\x02\\x8cE7\\x06\\xde\\xa2\\xe8\\x19\\n\\x80\\x1e\\x84',\n",
    "        '\\xee\\xdch\\xb5\\x01\\xe7\\xec\\xe6\\xd6g\\xf0\\x15\\xe9;\\x9c\\xd6n\\xdfd\\xab\\x11e\\x98\\xda\\x19nwT\\xbb\\xd6(7N\\x1cU\\xabT+\\xef8\\xaa',\n",
    "        '\\xe59[\\x8dQ\\x11p\\xa8DOv!e\\xa9\\xee9\\xa1\\xdb\\x16+\\xeee\\x02\\x9a\\xe5\\xee\\x8e\\xcd\\xbcf\\xfd\\xb0\\xd9\\x955\\x9a\\x9e\\xe3\\x98)*W',\n",
    "        '\\xad\\xcf\\x08d\\xc4\\x0c\\xf1;>x\\x11\\xcd\\xaa\\x834Q\\x9cFh2\\x17n\\x0c\\x86\\x91\\x02\\x14\\x83|\\x7f\\xdf0\\xdd}\\x10\\x96\\xe1\\x14X\\x17',\n",
    "        '\\xab\\xd6\\x0fOHK2\\xc7\\x06j-\\xf2\\xcf\\xf8\\xd7\\xb1\\x9d\\xaa\\xd1\\xaa\\x94+\\x17~.\\'\\x12\\r\\x8a1\\xcf\\x14\\x82\\x9d<\\x9b\\xaa\\xf0{p',\n",
    "        '\\x80\\xc2Tf*D+\\xc2\\x1f\\xaf\\x8b@\\xd4\\x8ea\\xfd\\x18z\\xa5\\xe5\\xf9,\\xed\\xf7\\xf4\\xac:|\\xce!\\xd9\\x8b)\\x04\\xc8W\\x07;0vB\\xd2\\x82',\n",
    "        '\\r^ \\xa7\\xdd|[\\xfe\\x04\\xcd\\x0ed,'\n",
    "    ])\n",
    "data = eval(data.decode('zip'))\n",
    "db.drop_collection('movies')\n",
    "collection = db.movies\n",
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymongo.cursor.Cursor object at 0x7f6bd4657450>\n"
     ]
    }
   ],
   "source": [
    "# type your code here\n",
    "actor = collection.find({\"person\":{\"name\":\"Tom Hanks\"}})\n",
    "list1 = actor\n",
    "list1 = list(collection.aggregate([\n",
    "            {\"$match\": {\"persons.name\": \"Tom Hanks\"}}\n",
    "        ]))\n",
    "#collection = db.persons\n",
    "actor = collection.find({\"name\":\"Tom Hanks\"})\n",
    "collection.update_one({\"persons.name\":\"Tom Hanks\"}, {\"$set\":{\"films\":list1}})\n",
    "#collection = db.movies\n",
    "print actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Incorrect query\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in collection.find():\n",
    "    del(i['_id'])\n",
    "    results.append(i)\n",
    "    \n",
    "Test.assertEqualsHashed(results, '0c7cd8639a01f99485544fc3fb0a5909cccc61a5','Incorrect query', \"Exercise 1.3 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation:\n",
    "\n",
    "Aggregations operations process data records and return computed results. Aggregation operations group values from multiple documents together, and can perform a variety of operations on the grouped data to return a single result. \n",
    "\n",
    "`aggregate()` method performs an aggregation using the aggregation framework on this collection. The `aggregate()` method accepts as its argument an array of stages, where each stage, processed sequentially, describes a data processing step.\n",
    "\n",
    "Following are the basic pipeline operators and let us make use of these operators over the sample data which we created. We are not going to discuss about Map-Reduce in this post.\n",
    "\n",
    "* `$match`: this is similar to `find_one()` or `find_many()` methods and SQL's `WHERE` clause; basically this filters the data which is passed on to the next operator. There can be multiple `$match` operators in the pipeline.\n",
    "* `$unwind`: this is used to unwind document that are using arrays; when using an array the data is kind of pre-joinded and this operation will be undone with this to have individual documents again. \n",
    "* `$group`: the group pipeline operator is similar to the SQL's `GROUP BY` clause; is equivalent to `group()` method. The full list of Group Accumulator Operators you can find [here](https://docs.mongodb.org/manual/reference/operator/aggregation/group/).\n",
    "* `$skip`: with this it is possible to skip forward in the list of documents for a given amount of documents; is equivalent to `skip()` method mentioned above.\n",
    "* `$limit`: this limits the amount of documents to look at by the given number starting from the current position; is equivalent to `limit()` method.\n",
    "* `$sort`: sorts the documents; is equivalent to `sort()` method.\n",
    "* `$project`: used to select some specific fields from a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('5c5090d364888406f3e1bcf0'),\n",
       "  u'continuation': True,\n",
       "  u'country': u'France',\n",
       "  u'duration_min': 86,\n",
       "  u'episodes': [u'Taxi', u'Taxi 2', u'Taxi 3', u'Taxi 4'],\n",
       "  u'lang': u'French',\n",
       "  u'persons': [{u'born': 1961,\n",
       "    u'country': u'France',\n",
       "    u'name': u'Samy Naceri'}],\n",
       "  u'released': 1998,\n",
       "  u'title': u'Taxi'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.aggregate([{\"$match\": {\"title\": \"Taxi\"}}]))\n",
    "# The same as collection.find_one({\"title\": \"Taxi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('5c5090d364888406f3e1bcec'),\n",
       "  u'country': u'USA',\n",
       "  u'duration_min': 142,\n",
       "  u'lang': u'English',\n",
       "  u'persons': [{u'born': 1956,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Tom Hanks',\n",
       "    u'relation': u'ACTED_IN',\n",
       "    u'role': u'Forrest Gump'},\n",
       "   {u'born': 1955,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Gary Sinise',\n",
       "    u'relation': u'ACTED_IN',\n",
       "    u'role': u'Lieutenant Dan Taylor'},\n",
       "   {u'born': 1952,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Robert Zemeckis',\n",
       "    u'relation': u'DIRECTED'}],\n",
       "  u'released': 1994,\n",
       "  u'title': u'Forrest Gump'},\n",
       " {u'_id': ObjectId('5c5090d364888406f3e1bced'),\n",
       "  u'box_office_Mdol': 290.7,\n",
       "  u'country': u'USA',\n",
       "  u'duration_min': 188,\n",
       "  u'lang': u'English',\n",
       "  u'persons': [{u'born': 1956,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Tom Hanks',\n",
       "    u'relation': u'ACTED_IN',\n",
       "    u'role': u'Paul Edgecomb'},\n",
       "   {u'born': 1955,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Gary Sinise',\n",
       "    u'relation': u'ACTED_IN',\n",
       "    u'role': u'Burt Hammersmith'},\n",
       "   {u'born': 1957,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Michael Clarke Duncan',\n",
       "    u'relation': u'ACTED_IN',\n",
       "    u'role': u'John Coffey'},\n",
       "   {u'born': 1959,\n",
       "    u'country': u'USA',\n",
       "    u'name': u'Frank Darabont',\n",
       "    u'relation': u'DIRECTED'}],\n",
       "  u'released': 1999,\n",
       "  u'title': u'The Green Mile'}]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all movies on English where Tom Hanks was acked in\n",
    "list(collection.aggregate([\n",
    "            {\"$match\": {\"lang\": \"English\"}},\n",
    "            {\"$match\": {\"persons.name\": \"Tom Hanks\"}}\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': u'French', u'count': 1, u'titles': [u'Taxi']},\n",
       " {u'_id': u'English',\n",
       "  u'count': 4,\n",
       "  u'titles': [u'Forrest Gump',\n",
       "   u'The Green Mile',\n",
       "   u'Inseption',\n",
       "   u'The Matrix']}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate movies amount with different languages using $group\n",
    "list(collection.aggregate([\n",
    "            {\"$group\": {\"_id\": \"$lang\", \"count\": {\"$sum\": 1}, \"titles\": {\"$push\": \"$title\"}}}\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'_id': ObjectId('5c5090d364888406f3e1bcee'),\n",
       "  u'persons': [{u'name': u'Leonardo DiCaprio'}],\n",
       "  u'released': 2010,\n",
       "  u'size': 1,\n",
       "  u'title': u'Inseption'},\n",
       " {u'_id': ObjectId('5c5090d364888406f3e1bcef'),\n",
       "  u'persons': [{u'name': u'Keanu Reeves'}, {u'name': u'Laurence Fishburne'}],\n",
       "  u'released': 1999,\n",
       "  u'size': 2,\n",
       "  u'title': u'The Matrix'},\n",
       " {u'_id': ObjectId('5c5090d364888406f3e1bced'),\n",
       "  u'persons': [{u'name': u'Tom Hanks'},\n",
       "   {u'name': u'Gary Sinise'},\n",
       "   {u'name': u'Michael Clarke Duncan'},\n",
       "   {u'name': u'Frank Darabont'}],\n",
       "  u'released': 1999,\n",
       "  u'size': 4,\n",
       "  u'title': u'The Green Mile'},\n",
       " {u'_id': ObjectId('5c5090d364888406f3e1bcf0'),\n",
       "  u'persons': [{u'name': u'Samy Naceri'}],\n",
       "  u'released': 1998,\n",
       "  u'size': 1,\n",
       "  u'title': u'Taxi'}]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Include only \"title\" and \"name\" of \"persons\" and sort them by  \n",
    "list(collection.aggregate([\n",
    "            {\"$project\": {\"title\": 1, \"persons.name\": 1, \"released\": 1, \"size\": {\"$size\": \"$persons\"}}},\n",
    "            {\"$sort\": {\"released\": -1,   # descending order\n",
    "                       \"size\": 1}},      # ascending order\n",
    "            {\"$limit\": 4}\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise 1.4:\n",
    "\n",
    "> Calculate the average born year of all persons only for those movies where there are at least two person set. Display results in descending order by the released year of the movie. You need write result to a Python list `results` with dictionaries containing keys `\"title\"`, `\"released\"` and `\"born_avg\"`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f6bd45b9f50>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ''.join([\n",
    "        'x\\x9c\\xbdUM\\x8f\\xda0\\x10\\xfd+\\xbe\\xe5\\xb2B\\x10\\xc2Wo[\\xbe\\x96\\x16P\\xb5\\xd0KW\\x08\\x99d \\x16\\xc98\\x9a\\xd8\\x15h\\xc5\\x7f',\n",
    "        '\\xafc\\x104!T\\xa0\\xd5\\xf6\\xe6\\x8cg\\xe6\\xcd\\x9by\\xe3\\xbc\\xbdk\\'\\xe2\\xb8q\\xbe0\\xed\\xf4q\\x13\\x894t\\x9e\\xcc9\\x01J%\\xa6\\xc6',\n",
    "        '\\xfef\\\\\\x90\\xc7`]\\xe62f/\\x1c\\xb7\\xa9u\\xf2\\xa5FE{{\\xf3s\\xf6lm+Ih\\x0c\\xb5N\\xa3\\x99}\\x92\\x8c\\x8e\\x91\\x03I\\x04\\xa9bC\\x1d',\n",
    "        \"\\'\\xd6q-\\xa2\\xd8\\xe6/\\xb9\\x9b\\x87\\xc0\\x86\\x04\" + '\\x80l\"L\\xfc\\xc2f\\x82\\x88+!\\xd1f{\\xee\\xce\\xfb\\xbd\\xe5h\\xea\\x1c\\x9e',\n",
    "        '\\xd8\\xfb\\xdf\\xa0\\x8d\\x1c\\xe8X\\x80V\\x80\\x1c\\x15\\xebqds\\xbe\\x8f$Y\\x843\\xa3!\\xa7=\\x9b\\t\\x14)8\\xb7a\\xca\\xd8\\x16\\xa1\\xdd',\n",
    "        '\\xab\\xf0\\xde\\xe8\\xb5\\x9fe\\xc8#\\xbe\\xca\\x15\\x90b\\xbf \\x06\\x7f+\\xca;yX\\xdc\\xea\\xaf\\x12\\xeaVG\\r6\\xf0\\x14\\x02[N\\xc7\\xcbL',\n",
    "        '\\x81&[\\xce2\\x16\\xb6J\\xcf=V]:\\xf3K\\xeaB\\xffo\\xcfz\\xb7\\x94\\xeb\\xb5\\xf0a9\\tdd\\xee\\xdcN\\xb5\\xd2\\xba\\xae\\xa5\\xf3)\\x92\\xfa',\n",
    "        '\\xc1u\\xc4\\xfa\\xc1\\x06|\\x19\\xaf\\xfe\\x9b\\xa6\\xbej3\\xbc\\x17\\x1e\\xc7\\x86N,T\\xf8Yrj\\xe5P\\xbf\\xc9\\x10Y\\xd74\\x1b\\xf6y\\xc0\\x89',\n",
    "        '\\xf0C\\x0e\\x11\\xebF\\x9c\\xb6\\xc0z\\x1a}\\x8e\\x1f\\x84\\xee\\xdc\\xa9\\xe4\\x01\\x99\\xb9\\x99\\xcd\"\\xbe\\x92\\xa8\\xfe!\\xe4\\xa2\\x0c\\xdb',\n",
    "        '\\xed\\xbbd8\\xc2\\x14\\x12[\\xc3\\xfd\\nl\\xbb\\x8dJ\\xa3\\xa0@\\xb7Z\\xab^+\\xf0\\xcc\\xb7\\xe5\\xe5X\\x8dA\"\\xa7@\\xb2\\x9e\\xe8\\xf2\\x84',\n",
    "        '\\x84|\\x80\\x98w\\x1f\\xb1L\\x8b\\x13\\xaeH\\xec\\x1e`\\xe65\\xebGf7h4\\xbd\\x9cb\\xa6 \\xf3\\xd3\\xfa\\x0e\\x1c5{\\x05\\xf8\\r\\xe9\\xc7\\x04',\n",
    "        '\\xd2\\xac\\xe5\\x90&\\x92\\x92\\x10t\\x9a\\x87\\x1bsM\\x80>\\xb0\\x81\\xe1\\xbf\\xd2\\x84\\x0f/\\x84\\xedp\\xc2IeT\\xebG\\x17T\\x02\\xf5%\\x81',\n",
    "        '\\\\3\\x13F\\xa7e+N\\xa3U\\xadTK\\x1e\\xa3\\xc2\\x88\\x06Y\\x99e\\x7f\\xbd\\x02\\xdf3\\xb3\\x19\\x8f\\xf7l\\xca} qUx\\xb6\\x12>\\x94\\xbc\\xdf',\n",
    "        '\\xa7\\x8b\\x82\\x0e\\xf8N\\x94<\\xdd\\xed\\xcc\\x04\\x89He\\x00\\xa7\\xe7\\xec\\xec\\x99\\x1d\\x98{9\\xd6/G\\xcfY\\x944iN\\x1aJ\\x9a\\xd3n',\n",
    "        '\\x1e\\x16\\x7f\\x00\\xc8}\\x836'\n",
    "    ])\n",
    "data = eval(data.decode('zip'))\n",
    "db.drop_collection('movies')\n",
    "collection = db.movies\n",
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO check this answer hash\n",
    "Test.assertEqualsHashed(results, 'fec785dfaa874101ef918e84466e309a28d3dfa4','Incorrect query', \"Exercise 1.4 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helpfull commands:\n",
    "\n",
    "1\\) If you need to get some statistics about your databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 1527.111111111111,\n",
       " u'collections': 3,\n",
       " u'dataFileVersion': {u'major': 4, u'minor': 5},\n",
       " u'dataSize': 13744,\n",
       " u'db': u'cinema',\n",
       " u'extentFreeList': {u'num': 0, u'totalSize': 0},\n",
       " u'fileSize': 67108864,\n",
       " u'indexSize': 8176,\n",
       " u'indexes': 1,\n",
       " u'nsSizeMB': 16,\n",
       " u'numExtents': 4,\n",
       " u'objects': 9,\n",
       " u'ok': 1.0,\n",
       " u'storageSize': 90112}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'dbstats': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\) To get collection statistics use the collstats command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'avgObjSize': 2697,\n",
       " u'count': 5,\n",
       " u'indexSizes': {u'_id_': 8176},\n",
       " u'lastExtentSize': 65536,\n",
       " u'nindexes': 1,\n",
       " u'ns': u'cinema.movies',\n",
       " u'numExtents': 2,\n",
       " u'ok': 1.0,\n",
       " u'paddingFactor': 1.004,\n",
       " u'size': 13488,\n",
       " u'storageSize': 73728,\n",
       " u'systemFlags': 1,\n",
       " u'totalIndexSize': 8176,\n",
       " u'userFlags': 1}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.command({'collstats': 'movies'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\) To copy a database within a single mongod process, or between mongod servers, simply connect to the target mongod and use the `command()` method:\n",
    "\n",
    "    client.admin.command('copydb',\n",
    "                         fromdb='source_db_name',\n",
    "                         todb='target_db_name')\n",
    "\n",
    "4\\) To copy from a different mongod server that is not password-protected:\n",
    "\n",
    "    client.admin.command('copydb',\n",
    "                         fromdb='source_db_name',\n",
    "                         todb='target_db_name',\n",
    "                         fromhost='source.example.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\) Indexes support the efficient resolution of queries. Without indexes, MongoDB must scan every document of a collection to select those documents that match the query statement. This scan is highly inefficient and require the mongodb to process a large volume of data.\n",
    "\n",
    "Indexes are special data structures, that store a small portion of the data set in an easy to traverse form. The index stores the value of a specific field or set of fields, ordered by the value of the field as specified in index.\n",
    "\n",
    "Use the `create_index()` method to create an index on a collection. Indexes can support the efficient execution of queries. MongoDB automatically creates an index on the `_id` field upon the creation of a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'films_1'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.create_index([(\"films\", pymongo.ASCENDING)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\) `mongodump` is a utility for creating a binary export of the contents of a database. \n",
    "\n",
    "To dump your database for backup you call one of these commands on your terminal\n",
    "\n",
    "    mongodump --db <database_name> --collection <collection_name>\n",
    "\n",
    "This command will make a dump of given database in JSON and BSON formats. To import your backup file to mongodb you can use the following command on your terminal\n",
    "\n",
    "    mongorestore --db <database_name> <path_to_bson_file>\n",
    "\n",
    "You can also use gzip for taking backup of one collection and compressing the backup on the fly:\n",
    "\n",
    "    mongodump --db <database_name> --collection <collection_name> --out - | gzip > <dump_name>.gz\n",
    "\n",
    "or with a date in the file name:\n",
    "\n",
    "    mongodump --db <database_name> --collection <collection_name> --out - | gzip > dump_`date \"+%Y-%m-%d\"`.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Exercise 1.5:\n",
    "\n",
    "> Based on the material learned in the lesson devoted to the Twitter API you need to do the following tasks: \n",
    "\n",
    "> **1\\.** Create a new MongoDB database \"twitter\\_db\" with two new collections \"tweets\" and \"users\". The collection \"tweets\" will contain data about last appeared `N = 2500` tweets with hashtags _\"BigData\"_ and _\"DataScience\"_. The collection \"users\" will contain data about users which created the tweet, i.e. authors. \n",
    "\n",
    "> **2\\.** Using `requests` URL queries or `tweepy`'s `search()` method collect last appeared `N` tweets with hashtags _\"BigData\"_ and _\"DataScience\"_. It may be easily done as follows:\n",
    "\n",
    ">    `tweets = []`<br></br>\n",
    ">    `last_id = 0`<br></br>\n",
    "\n",
    ">    `while len(tweets) < N:`<br></br>\n",
    ">    <span style=\"margin-left:2em\"></span>`response = api.search(q=['BigData', 'DataScience'], since_id=last_id, count=100)`<br></br>\n",
    ">    <span style=\"margin-left:2em\"></span>`last_id = str(results[-1].id)`<br></br>\n",
    ">    <span style=\"margin-left:2em\"></span>`tweets.extend(response)`\n",
    "\n",
    "> where `api = tweepy.API(auth)` as written in the previous lesson **Lesson 8.1 - Work with Twitter API in Python.ipynb**. If `twwets` list contains over `N` records, take the first `N` of them. Try go get this result using `requests` library.\n",
    "\n",
    "> **3\\.** Collection \"tweets\" should contain the following fields from available tweet fields:\n",
    "\n",
    ">    * `'created_at'`;\n",
    ">    * `'author_id'` (corresponds to `author.id`);\n",
    ">    * `'author_name'` (corresponds to `author.name`);\n",
    ">    * `'retweet_count'`;\n",
    ">    * `'id'`;\n",
    ">    * `'lang'`;\n",
    ">    * `'source'`;\n",
    ">    * `'text'`.\n",
    "\n",
    "> Necessary fields in the collection \"users\":\n",
    "\n",
    ">    * `'created_at'`;\n",
    ">    * `'id'` (means user's ID);\n",
    ">    * `'name'`;\n",
    ">    * `'description'`;\n",
    ">    * `'followers_count'`;\n",
    ">    * `'friends_count'`;\n",
    ">    * `'lang'`;\n",
    ">    * `'profile_image_url'`;\n",
    ">    * `'location'`;\n",
    ">    * `'time_zone'`;\n",
    ">    * `'tweets'` (is an array of tweets ids from \"tweets\" colection).\n",
    "\n",
    "> On this step you need fill both collection with respect data. Pay your attention, one user could create more than one tweet from \"tweets\" collection. IDs of all these tweets should be written to `'tweets'` field for the respective user.\n",
    "\n",
    "> **4\\.** Create a new collection `\"bigdata_tweets_date1_date2\"` with tweets that contain only \"#BigData\" hashtag, are written in English, where not retweeted and was created during the last hour. `date1` corresponds the full date in format `'%Y_%m_%d_%H_%M_%S'` of the first created tweet and `date2` is the full date of last created tweet in the obtained `\"bigdata_tweets_date1_date2\"` collection. <br></br>\n",
    "> _**Hint:**_ The value of `'created_at'` field has the form and type of datetime.datetime object. \n",
    "\n",
    "> **5\\.** Find TOP 5 tweets (from \"tweets\" collection) with the largest amount of retweets for each language. If there are a few tweets with the same retweets amount, sort them by `\"author_name\"` in descending order. Display its text, author name, date of creation and retweets amount. Put result into the Python list `result_5` containing dictionaries of such structure \n",
    "\n",
    "> <span style=\"margin-left: 30px\"></span>`{'language': `<br></br>\n",
    "> <span style=\"margin-left: 100px\"></span>`[`<br></br>\n",
    "> <span style=\"margin-left: 110px\"></span>`{`<br></br>\n",
    "> <span style=\"margin-left: 115px\"></span>`'author_name': ...,`<br></br>\n",
    "> <span style=\"margin-left: 115px\"></span>`'created_at': ...,`<br></br>\n",
    "> <span style=\"margin-left: 115px\"></span>`'retweet_count': ...,`<br></br>\n",
    "> <span style=\"margin-left: 115px\"></span>`'text': ....`<br></br>\n",
    "> <span style=\"margin-left: 115px\"></span>`}, `<br></br>\n",
    "> <span style=\"margin-left: 110px\"></span>`...`<br></br>\n",
    "> <span style=\"margin-left: 105px\"></span>`]`<br></br>\n",
    "> <span style=\"margin-left: 35px\"></span>`}`\n",
    "\n",
    "> for each unique language.\n",
    "\n",
    "> **6\\.** For each timezone (when it is defined, i.e. is not `None`) find the user with maximal average value of friends and followers who pointed out \"en\" or \"es\" or \"fr\" in the field `\"lang\"`. Put result into the Python list `result_6` containing dictionaries of such structure\n",
    "\n",
    "> <span style=\"margin-left: 30px\"></span>`{'timezone name':`<br></br>\n",
    "> <span style=\"margin-left: 160px\"></span>`{`<br></br>\n",
    "> <span style=\"margin-left: 165px\"></span>`'name': ...,`<br></br>\n",
    "> <span style=\"margin-left: 165px\"></span>`'profile_image_url': ...,`<br></br>\n",
    "> <span style=\"margin-left: 165px\"></span>`'tweets': `<br></br>\n",
    "> <span style=\"margin-left: 235px\"></span>`[`<br></br>\n",
    "> <span style=\"margin-left: 245px\"></span>`{`<br></br>\n",
    "> <span style=\"margin-left: 250px\"></span>`'created_at': ...,`<br></br>\n",
    "> <span style=\"margin-left: 250px\"></span>`'text': ...`<br></br>\n",
    "> <span style=\"margin-left: 250px\"></span>`},`<br></br>\n",
    "> <span style=\"margin-left: 245px\"></span>`...`<br></br>\n",
    "> <span style=\"margin-left: 240px\"></span>`]`<br></br>\n",
    "> <span style=\"margin-left: 165px\"></span>`},`<br></br>\n",
    "> <span style=\"margin-left: 160px\"></span>`...`<br></br>\n",
    "> <span style=\"margin-left: 35px\"></span>`}`\n",
    "\n",
    "> for each unique language.\n",
    "\n",
    "> Display his name, avatar and the list of tweets (text and date of creation of the tweet) from \"tweets\" collection. <br></br>\n",
    "> _**Hint:**_ You may display image by url in the following way:\n",
    "\n",
    "> `In [1]: from IPython.display import HTML`<br></br>\n",
    "> <span style=\"margin-left:4.5em\"></span>`bg = api.get_user(\"BillGates\")`<br></br>\n",
    "> <span style=\"margin-left:4.5em\"></span>`print bg.name`<br></br>\n",
    "> <span style=\"margin-left:4.5em\"></span>`HTML('<img src=\"' + bg.profile_banner_url + '\" width=\"700\">')`<br></br>\n",
    "> <span style=\"margin-left:4.5em\"></span>`Bill Gates`<br></br>\n",
    "> `Out [1]:`\n",
    "> <img src=\"images/bill_gates.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tweepy.api.API object at 0x7fc30561ac10>\n",
      "My name is Dmitriy Kisil\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "# type your code here\n",
    "consumer_key = 'o7ApzFDk58YKYoCXR7au2Qa8o'\n",
    "consumer_secret = 'sCruk5UCcQpuyL7NWPizcgfDHeJEG5CEioG43j6iNOmUymJsVa'\n",
    "access_token = '1437963396-DdboBDabBE3KyUqHd8Zz3sr8MxVpKDwVRJRUjiC'\n",
    "access_token_secret = 'R4GmIhhjx2doAZFam1EMrgFuxFe5u7zXRBR7dLEgGjqSp'\n",
    "# Authorization to consumer key and consumer secret \n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret) \n",
    "# Access to user's access key and access secret \n",
    "auth.set_access_token(access_token, access_token_secret) \n",
    "# Calling api \n",
    "api = tweepy.API(auth)\n",
    "print api\n",
    "# If the authentication was successful, you should see the name of the account print out\n",
    "print \"My name is\", api.me().name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'local', u'cinema', u'admin', u'twitter_db']\n",
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'twitter_db'), u'tweets')\n",
      "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'twitter_db'), u'users')\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "twitter_db = client[\"twitter_db\"]\n",
    "print client.database_names()\n",
    "tweets = twitter_db.tweets\n",
    "print tweets\n",
    "users = twitter_db.users\n",
    "print users\n",
    "print twitter_db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['contributors', 'truncated', 'text', 'is_quote_status', 'in_reply_to_status_id', 'id', 'favorite_count', '_api', 'author', '_json', 'coordinates', 'entities', 'in_reply_to_screen_name', 'id_str', 'retweet_count', 'in_reply_to_user_id', 'favorited', 'retweeted_status', 'source_url', 'user', 'geo', 'in_reply_to_user_id_str', 'lang', 'created_at', 'in_reply_to_status_id_str', 'place', 'source', 'retweeted', 'metadata']\n",
      "[u'symbols', u'user_mentions', u'hashtags', u'urls']\n",
      "['follow_request_sent', 'has_extended_profile', 'profile_use_background_image', '_json', 'time_zone', 'id', 'description', '_api', 'verified', 'profile_text_color', 'profile_image_url_https', 'profile_sidebar_fill_color', 'is_translator', 'geo_enabled', 'entities', 'followers_count', 'protected', 'id_str', 'default_profile_image', 'listed_count', 'lang', 'utc_offset', 'statuses_count', 'profile_background_color', 'friends_count', 'profile_link_color', 'profile_image_url', 'notifications', 'default_profile', 'profile_background_image_url_https', 'profile_background_image_url', 'name', 'is_translation_enabled', 'profile_background_tile', 'favourites_count', 'screen_name', 'url', 'created_at', 'contributors_enabled', 'location', 'profile_sidebar_border_color', 'translator_type', 'following']\n",
      "['follow_request_sent', 'has_extended_profile', 'profile_use_background_image', '_json', 'time_zone', 'id', 'description', '_api', 'verified', 'profile_text_color', 'profile_image_url_https', 'profile_sidebar_fill_color', 'is_translator', 'geo_enabled', 'entities', 'followers_count', 'protected', 'id_str', 'default_profile_image', 'listed_count', 'lang', 'utc_offset', 'statuses_count', 'profile_background_color', 'friends_count', 'profile_link_color', 'profile_image_url', 'notifications', 'default_profile', 'profile_background_image_url_https', 'profile_background_image_url', 'name', 'is_translation_enabled', 'profile_background_tile', 'favourites_count', 'screen_name', 'url', 'created_at', 'contributors_enabled', 'location', 'profile_sidebar_border_color', 'translator_type', 'following']\n",
      "3075551314\n",
      "Megg\n",
      "3075551314\n",
      "Megg\n",
      "Megg\n"
     ]
    }
   ],
   "source": [
    "# type your code here\n",
    "\n",
    "tweets_list = []\n",
    "list1 = []\n",
    "last_id = 0\n",
    "while len(tweets_list) < 100:\n",
    "    response = api.search(q=['BigData', 'DataScience'], count=1)\n",
    "    #print response.id\n",
    "    #last_id = str(response[-1].id)\n",
    "    tweets_list.extend(response)\n",
    "#print api.rate_limit_status()\n",
    "print len(tweets_list)\n",
    "print tweets_list[0].__dict__.keys()\n",
    "print tweets_list[0].entities.keys()\n",
    "#print tweets[0].user.keys()\n",
    "#print tweets[0].author.keys()\n",
    "print tweets_list[0].user.__dict__.keys()\n",
    "print tweets_list[0].author.__dict__.keys()\n",
    "print tweets_list[0].author.id\n",
    "print tweets_list[0].author.name\n",
    "print tweets_list[0].user.id\n",
    "print tweets_list[0].user.name\n",
    "\n",
    "for i in range(len(tweets_list)):\n",
    "    list1.append(tweets_list[i].author.name)\n",
    "\n",
    "print list1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = twitter_db.tweets\n",
    "\n",
    "users = twitter_db.users\n",
    "\n",
    "for i in range(len(tweets_list)):\n",
    "    tweets.insert_one({\"created_at\": tweets_list[i].created_at, \"author_id\": tweets_list[i].author.id, \n",
    "                       \"author_name\": list1[i],\"retweet_count\": tweets_list[i].retweet_count,\n",
    "                       \"id\": tweets_list[i].id, \"lang\": tweets_list[i].lang, \"source\": tweets_list[i].source,\n",
    "                       \"text\": tweets_list[i].text})\n",
    "    users.insert_one({\"created_at\": tweets_list[i].user.created_at, \"id\": tweets_list[i].user.id, \"name\": tweets_list[i].user.name,\n",
    "                      \"description\": tweets_list[i].user.description, \"followers_count\":tweets_list[i].user.followers_count,\n",
    "                      \"friends_count\": tweets_list[i].user.friends_count, \"lang\": tweets_list[i].user.lang, \n",
    "                      \"profile_image_url\": tweets_list[i].user.profile_image_url, \"location\": tweets_list[i].user.location,\n",
    "                      \"time_zone\": tweets_list[i].user.time_zone, \"tweets\":tweets_list[i].id})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'lang': u'en', u'retweet_count': 562, u'text': u'RT @KirkDBorne: One of my all-time favorites &gt;&gt; The Most Complete List of the Best Cheat Sheets for #DataScientists covering #AI #NeuralNet\\u2026', u'created_at': datetime.datetime(2019, 1, 30, 14, 2, 37), u'author_name': u'Megg', u'source': u'Twitter Web App', u'author_id': 3075551314L, u'_id': ObjectId('5c51aef4648884071317efbd'), u'id': 1090611241402490880L}\n",
      "{u'lang': u'en', u'description': u'Sue\\xf1a, Siente, Mira', u'friends_count': 8, u'created_at': datetime.datetime(2015, 3, 6, 18, 52, 47), u'time_zone': None, u'profile_image_url': u'http://pbs.twimg.com/profile_images/573922103767994368/CBXjlh4a_normal.jpeg', u'followers_count': 226, u'location': u'', u'tweets': 1090611241402490880L, u'_id': ObjectId('5c51aef4648884071317efbe'), u'id': 3075551314L, u'name': u'Megg'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'system.indexes', u'tweets', u'users']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tweets.find_one()\n",
    "print users.find_one()\n",
    "twitter_db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_db.drop_collection(\"tweets\")\n",
    "twitter_db.drop_collection(\"users\")\n",
    "tweets = twitter_db[\"tweets\"]\n",
    "users = twitter_db[\"users\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Collection \"tweets\" should contain the following fields from available tweet fields:\n",
    "\n",
    "    'created_at';\n",
    "    'author_id' (corresponds to author.id);\n",
    "    'author_name' (corresponds to author.name);\n",
    "    'retweet_count';\n",
    "    'id';\n",
    "    'lang';\n",
    "    'source';\n",
    "    'text'.\n",
    "\n",
    "Necessary fields in the collection \"users\":\n",
    "\n",
    "    'created_at';\n",
    "    'id' (means user's ID);\n",
    "    'name';\n",
    "    'description';\n",
    "    'followers_count';\n",
    "    'friends_count';\n",
    "    'lang';\n",
    "    'profile_image_url';\n",
    "    'location';\n",
    "    'time_zone';\n",
    "    'tweets' (is an array of tweets ids from \"tweets\" colection).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'rate_limit_context': {u'access_token': u'1437963396-DdboBDabBE3KyUqHd8Zz3sr8MxVpKDwVRJRUjiC'}, u'resources': {u'feedback': {u'/feedback/show/:id': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/feedback/events': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}}, u'moments': {u'/moments/statuses/update': {u'reset': 1548857129, u'limit': 5, u'remaining': 5}, u'/moments/permissions': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}}, u'oauth': {u'/oauth/invalidate_token': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}}, u'tweet_prompts': {u'/tweet_prompts/show': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/tweet_prompts/report_interaction': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}}, u'live_pipeline': {u'/live_pipeline/events': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}}, u'friendships': {u'/friendships/outgoing': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friendships/no_retweets/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friendships/list': {u'reset': 1548857129, u'limit': 200, u'remaining': 200}, u'/friendships/show': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/friendships/incoming': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friendships/lookup': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'statuses': {u'/statuses/retweets_of_me': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/statuses/retweeters/ids': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/statuses/mentions_timeline': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/statuses/user_timeline': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/statuses/lookup': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/statuses/oembed': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/statuses/show/:id': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/statuses/friends': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/statuses/home_timeline': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/statuses/retweets/:id': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}}, u'help': {u'/help/tos': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/help/settings': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/help/privacy': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/help/configuration': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/help/languages': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'drafts': {u'/drafts/statuses/list': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/drafts/statuses/destroy': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/drafts/statuses/create': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/drafts/statuses/ids': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/drafts/statuses/update': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/drafts/statuses/show': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}}, u'contacts': {u'/contacts/uploaded_by': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/contacts/users_and_uploaded_by': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/contacts/delete/status': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/contacts/users': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/contacts/addressbook': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}}, u'friends': {u'/friends/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friends/following/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friends/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/friends/following/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'business_experience': {u'/business_experience/dashboard_settings/show': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/business_experience/keywords': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/business_experience/dashboard_settings/destroy': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/business_experience/dashboard_features': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/business_experience/dashboard_settings/update': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}}, u'application': {u'/application/rate_limit_status': {u'reset': 1548857129, u'limit': 180, u'remaining': 179}}, u'safety': {u'/safety/detection_feedback': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}}, u'collections': {u'/collections/list': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}, u'/collections/show': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}, u'/collections/entries': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}}, u'tweets': {u'/tweets/stream/filter/:instance_name': {u'reset': 1548857129, u'limit': 50, u'remaining': 50}, u'/tweets/stream/filter/rules/:instance_name/:rule_id': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/tweets/search/:product/:instance/counts': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/tweets/search/:product/:label': {u'reset': 1548857129, u'limit': 1800, u'remaining': 1800}, u'/tweets/stream/filter/rules/:instance_name/validation&POST': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/tweets/stream/filter/rules/:instance_name&DELETE': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/tweets/stream/filter/rules': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}, u'/tweets/stream/filter/rules/:instance_name&POST': {u'reset': 1548857129, u'limit': 450, u'remaining': 450}}, u'followers': {u'/followers/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/followers/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'mutes': {u'/mutes/users/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/mutes/users/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'saved_searches': {u'/saved_searches/show/:id': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/saved_searches/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/saved_searches/destroy/:id': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'blocks': {u'/blocks/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/blocks/ids': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'users': {u'/users/suggestions/:slug': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/users/lookup': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/users/search': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/users/suggestions/:slug/members': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/users/contributors/pending': {u'reset': 1548857129, u'limit': 2000, u'remaining': 2000}, u'/users/show/:id': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/users/suggestions': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/users/contributees/pending': {u'reset': 1548857129, u'limit': 200, u'remaining': 200}, u'/users/report_spam': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/users/profile_banner': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/users/derived_info': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'search': {u'/search/tweets': {u'reset': 1548856980, u'limit': 180, u'remaining': 80}}, u'lists': {u'/lists/subscribers/show': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/lists/subscriptions': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/lists/statuses': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/lists/members/show': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/lists/subscribers': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/lists/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/lists/show': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/lists/memberships': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/lists/members': {u'reset': 1548857129, u'limit': 900, u'remaining': 900}, u'/lists/ownerships': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'traffic': {u'/traffic/map': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'custom_profiles': {u'/custom_profiles/list': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/custom_profiles/show': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}}, u'favorites': {u'/favorites/list': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}}, u'device': {u'/device/token': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'webhooks': {u'/webhooks/subscriptions/direct_messages': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'geo': {u'/geo/similar_places': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/geo/id/:place_id': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/geo/reverse_geocode': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/geo/search': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'account': {u'/account/verify_credentials': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/account/settings': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account/personalization/sync_optout_settings&POST': {u'reset': 1548857129, u'limit': 200, u'remaining': 200}, u'/account/login_verification_enrollment': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account/update_profile': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'live_video_stream': {u'/live_video_stream/status/:id': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}}, u'i': {u'/i/config': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'trends': {u'/trends/available': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/trends/closest': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}, u'/trends/place': {u'reset': 1548857129, u'limit': 75, u'remaining': 75}}, u'direct_messages': {u'/direct_messages/show': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/direct_messages/mark_read': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}, u'/direct_messages/broadcasts/show': {u'reset': 1548857129, u'limit': 60, u'remaining': 60}, u'/direct_messages/subscribers/lists/show': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/direct_messages': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/direct_messages/broadcasts/list': {u'reset': 1548857129, u'limit': 60, u'remaining': 60}, u'/direct_messages/sent_and_received': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/direct_messages/subscribers/lists/members/ids': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/direct_messages/subscribers/show': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/direct_messages/subscribers/lists/list': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/direct_messages/events/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/direct_messages/broadcasts/statuses/list': {u'reset': 1548857129, u'limit': 60, u'remaining': 60}, u'/direct_messages/subscribers/ids': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}, u'/direct_messages/subscribers/lists/members/show': {u'reset': 1548857129, u'limit': 1000, u'remaining': 1000}, u'/direct_messages/sent': {u'reset': 1548857129, u'limit': 300, u'remaining': 300}, u'/direct_messages/broadcasts/statuses/show': {u'reset': 1548857129, u'limit': 60, u'remaining': 60}, u'/direct_messages/events/show': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'sandbox': {u'/sandbox/account_activity/webhooks/:id/subscriptions': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}}, u'media': {u'/media/upload': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}}, u'graphql&POST': {u'/graphql&POST': {u'reset': 1548857129, u'limit': 2500, u'remaining': 2500}}, u'account_activity': {u'/account_activity/all/:instance_name/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/webhooks/:id/subscriptions': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}, u'/account_activity/direct_messages/:instance_name/subscriptions': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/all/:instance_name/subscriptions': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}, u'/account_activity/webhooks/:id/subscriptions/all/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/direct_messages/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/direct_messages/:instance_name/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/webhooks/:id/subscriptions/direct_messages': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}, u'/account_activity/webhooks/:id/subscriptions/all': {u'reset': 1548857129, u'limit': 500, u'remaining': 500}, u'/account_activity/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/webhooks/:id/subscriptions/direct_messages/list': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}, u'/account_activity/all/webhooks': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'auth': {u'/auth/csrf_token': {u'reset': 1548857129, u'limit': 15, u'remaining': 15}}, u'guide': {u'/guide': {u'reset': 1548857129, u'limit': 180, u'remaining': 180}}}}\n"
     ]
    }
   ],
   "source": [
    "# type your code here\n",
    "print api.rate_limit_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. \"users\" and/or \"tweets\" collections were not found\n",
      "1 test failed. Incorrect records amount in \"twitter\" collection\n",
      "1 test passed. Exercise 1.5.3 is successful\n"
     ]
    }
   ],
   "source": [
    "Test.existCollections(client, '\"users\" and/or \"tweets\" collections were not found', \"Exercise 1.5.1 is successful\")\n",
    "Test.countRecord('id', client, 'Incorrect records amount in \"twitter\" collection', \"Exercise 1.5.2 is successful\")\n",
    "Test.existField('id', client, 'Incorrect data in MongoDB', \"Exercise 1.5.3 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.bigDataTweets(client, 'Incorrect data in MongoDB', \"Exercise 1.5.4 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type your code here\n",
    "\n",
    "# result_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.top5Tweets(result_5, client, 'Incorrect data in MongoDB', \"Exercise 1.5.5 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type your code here\n",
    "\n",
    "# result_6 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.timeZoneTweets(result_6, client, 'Incorrect data in MongoDB', \"Exercise 1.5.6 is successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Presented by <a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"http://datascience-school.com\">datascience-school.com</a></h3></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
